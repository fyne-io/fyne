// Code generated by go run gen.go; DO NOT EDIT.

package async

import "sync"

// UnboundedInterfaceChan is a channel with an unbounded buffer for caching
// Interface objects.
type UnboundedInterfaceChan struct {
	in, out chan interface{}
	close   chan struct{}
	q       []interface{}

	estimateLock sync.Mutex
	estimate     int // a number guaranteed to be <= len(ch.q) at all times
}

const estimateInterfacePrecision = 10

// NewUnboundedInterfaceChan returns a unbounded channel with unlimited capacity.
func NewUnboundedInterfaceChan() *UnboundedInterfaceChan {
	ch := &UnboundedInterfaceChan{
		// The size of Interface is less than 16 bytes, we use 16 to fit
		// a CPU cache line (L2, 256 Bytes), which may reduce cache misses.
		in:    make(chan interface{}, 16),
		out:   make(chan interface{}, 16),
		close: make(chan struct{}),
	}
	go ch.processing()
	return ch
}

// In returns the send channel of the given channel, which can be used to
// send values to the channel.
func (ch *UnboundedInterfaceChan) In() chan<- interface{} { return ch.in }

// Out returns the receive channel of the given channel, which can be used
// to receive values from the channel.
func (ch *UnboundedInterfaceChan) Out() <-chan interface{} { return ch.out }

// Close closes the channel.
func (ch *UnboundedInterfaceChan) Close() { ch.close <- struct{}{} }

func (ch *UnboundedInterfaceChan) processing() {
	// This is a preallocation of the internal unbounded buffer.
	// The size is randomly picked. But if one changes the size, the
	// reallocation size at the subsequent for loop should also be
	// changed too. Furthermore, there is no memory leak since the
	// queue is garbage collected.
	ch.q = make([]interface{}, 0, 1<<10)
	for {
		select {
		case e, ok := <-ch.in:
			if !ok {
				// We don't want the input channel be accidentally closed
				// via close() instead of Close(). If that happens, it is
				// a misuse, do a panic as warning.
				panic("async: misuse of unbounded channel, In() was closed")
			}
			ch.q = append(ch.q, e)
		case <-ch.close:
			ch.closed()
			return
		}
		for len(ch.q) > 0 {
			select {
			case ch.out <- ch.q[0]:
				ch.q[0] = nil // de-reference earlier to help GC
				if (len(ch.q)%estimateInterfacePrecision == 1) || (len(ch.q) <= estimateInterfacePrecision) {
					ch.estimateLock.Lock()
					ch.estimate = len(ch.q) - 1
					ch.estimateLock.Unlock()
				}
				ch.q = ch.q[1:]
			case e, ok := <-ch.in:
				if !ok {
					// We don't want the input channel be accidentally closed
					// via close() instead of Close(). If that happens, it is
					// a misuse, do a panic as warning.
					panic("async: misuse of unbounded channel, In() was closed")
				}
				ch.q = append(ch.q, e)
				if len(ch.q)%estimateInterfacePrecision == 0 || (len(ch.q) <= estimateInterfacePrecision) {
					ch.estimateLock.Lock()
					ch.estimate = len(ch.q)
					ch.estimateLock.Unlock()
				}
			case <-ch.close:
				ch.closed()
				return
			}
		}
		// If the remaining capacity is too small, we prefer to
		// reallocate the entire buffer.
		if cap(ch.q) < 1<<5 {
			ch.q = make([]interface{}, 0, 1<<10)
		}
	}
}

// EstimatedLength returns the number guaranteed to be less than or equal to
// the number of items in the internal buffer ready to be consumed.
func (ch *UnboundedInterfaceChan) EstimatedLength() int {
	ch.estimateLock.Lock()
	result := ch.estimate
	ch.estimateLock.Unlock()
	return result
}

func (ch *UnboundedInterfaceChan) closed() {
	close(ch.in)
	for e := range ch.in {
		ch.q = append(ch.q, e)
	}
	for len(ch.q) > 0 {
		select {
		case ch.out <- ch.q[0]:
			ch.q[0] = nil // de-reference earlier to help GC
			ch.q = ch.q[1:]
		default:
		}
	}
	close(ch.out)
	close(ch.close)
}
